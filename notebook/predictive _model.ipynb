{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e79b866",
   "metadata": {},
   "source": [
    "# Insurance Risk-Based Pricing ML Pipeline\n",
    "### Task 4: Build and evaluate predictive models for dynamic, risk-based pricing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "248c00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, accuracy_score, \n",
    "                           precision_score, recall_score, f1_score, \n",
    "                           classification_report, confusion_matrix, roc_auc_score)\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18cca8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Insurance Risk-Based Pricing ML Pipeline...\n",
      "Data loaded successfully: (1000098, 46)\n",
      "Columns: ['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth', 'IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'PostalCode', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode', 'VehicleType', 'RegistrationYear', 'make', 'Model', 'Cylinders', 'cubiccapacity', 'kilowatts', 'bodytype', 'NumberOfDoors', 'VehicleIntroDate', 'AlarmImmobiliser', 'TrackingDevice', 'CapitalOutstanding', 'NewVehicle', 'SumInsured', 'TermFrequency', 'CalculatedPremiumPerTerm', 'ExcessSelected', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType', 'TotalPremium', 'TotalClaims']\n",
      "\n",
      "First few rows:\n",
      "   UnderwrittenCoverID  PolicyID     TransactionMonth  IsVATRegistered  \\\n",
      "0               145249     12827  2015-03-01 00:00:00             True   \n",
      "1               145249     12827  2015-05-01 00:00:00             True   \n",
      "2               145249     12827  2015-07-01 00:00:00             True   \n",
      "3               145255     12827  2015-05-01 00:00:00             True   \n",
      "4               145255     12827  2015-07-01 00:00:00             True   \n",
      "\n",
      "  Citizenship          LegalType Title Language                 Bank  \\\n",
      "0              Close Corporation    Mr  English  First National Bank   \n",
      "1              Close Corporation    Mr  English  First National Bank   \n",
      "2              Close Corporation    Mr  English  First National Bank   \n",
      "3              Close Corporation    Mr  English  First National Bank   \n",
      "4              Close Corporation    Mr  English  First National Bank   \n",
      "\n",
      "       AccountType  ...                    ExcessSelected CoverCategory  \\\n",
      "0  Current account  ...             Mobility - Windscreen    Windscreen   \n",
      "1  Current account  ...             Mobility - Windscreen    Windscreen   \n",
      "2  Current account  ...             Mobility - Windscreen    Windscreen   \n",
      "3  Current account  ...  Mobility - Metered Taxis - R2000    Own damage   \n",
      "4  Current account  ...  Mobility - Metered Taxis - R2000    Own damage   \n",
      "\n",
      "    CoverType            CoverGroup              Section  \\\n",
      "0  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
      "1  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
      "2  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
      "3  Own Damage  Comprehensive - Taxi  Motor Comprehensive   \n",
      "4  Own Damage  Comprehensive - Taxi  Motor Comprehensive   \n",
      "\n",
      "                           Product StatutoryClass StatutoryRiskType  \\\n",
      "0  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "1  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "2  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "3  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "4  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "\n",
      "   TotalPremium TotalClaims  \n",
      "0     21.929825         0.0  \n",
      "1     21.929825         0.0  \n",
      "2      0.000000         0.0  \n",
      "3    512.848070         0.0  \n",
      "4      0.000000         0.0  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "==================================================\n",
      "DATA EXPLORATION\n",
      "==================================================\n",
      "Dataset shape: (1000098, 46)\n",
      "\n",
      "Missing values:\n",
      "VehicleIntroDate    1000098\n",
      "dtype: int64\n",
      "\n",
      "Claims Analysis:\n",
      "Total policies: 1000098\n",
      "Policies with claims: 2788\n",
      "Claim frequency: 0.28%\n",
      "\n",
      "Correlation with TotalClaims:\n",
      "TotalPremium                0.121588\n",
      "CalculatedPremiumPerTerm    0.079787\n",
      "RegistrationYear            0.005197\n",
      "kilowatts                   0.003234\n",
      "UnderwrittenCoverID         0.003011\n",
      "PolicyID                    0.002941\n",
      "NumberOfDoors               0.001680\n",
      "cubiccapacity               0.001333\n",
      "PostalCode                  0.000412\n",
      "Cylinders                   0.000008\n",
      "Name: TotalClaims, dtype: float64\n",
      "==================================================\n",
      "FEATURE ENGINEERING\n",
      "==================================================\n",
      "Feature engineering completed\n",
      "New features created: VehicleAge, HasClaim, PremiumToSumInsuredRatio, ClaimToPremiumRatio, etc.\n",
      "==================================================\n",
      "FEATURE PREPARATION\n",
      "==================================================\n",
      "Cleaning numeric column: RegistrationYear\n",
      "Cleaning numeric column: Cylinders\n",
      "Cleaning numeric column: cubiccapacity\n",
      "Cleaning numeric column: kilowatts\n",
      "Cleaning numeric column: NumberOfDoors\n",
      "Cleaning numeric column: CapitalOutstanding\n",
      "Cleaning numeric column: SumInsured\n",
      "Cleaning numeric column: CalculatedPremiumPerTerm\n",
      "Cleaning numeric column: VehicleAge\n",
      "Cleaning numeric column: TransactionYear\n",
      "Cleaning numeric column: TransactionMonth_num\n",
      "Cleaning numeric column: PremiumToSumInsuredRatio\n",
      "Cleaning numeric column: ProvinceRisk\n",
      "Cleaning numeric column: MakeRisk\n",
      "Cleaning target column: TotalClaims\n",
      "Cleaning target column: TotalPremium\n",
      "Cleaning target column: CalculatedPremiumPerTerm\n",
      "Cleaning target column: SumInsured\n",
      "Cleaning target column: CapitalOutstanding\n",
      "Final feature matrix shape: (1000098, 28)\n",
      "Claim severity dataset shape: (2788, 28)\n",
      "Features used: ['RegistrationYear', 'Cylinders', 'cubiccapacity', 'kilowatts', 'NumberOfDoors', 'CapitalOutstanding', 'SumInsured', 'CalculatedPremiumPerTerm', 'VehicleAge', 'TransactionYear', 'TransactionMonth_num', 'PremiumToSumInsuredRatio', 'ProvinceRisk', 'MakeRisk', 'IsVATRegistered_encoded', 'LegalType_encoded', 'Gender_encoded', 'Province_encoded', 'VehicleType_encoded', 'make_encoded', 'bodytype_encoded', 'AlarmImmobiliser_encoded', 'TrackingDevice_encoded', 'NewVehicle_encoded', 'TermFrequency_encoded', 'CoverCategory_encoded', 'CoverType_encoded', 'Product_encoded']\n",
      "\n",
      "Data types after cleaning:\n",
      "TotalClaims: float64\n",
      "TotalPremium: float64\n",
      "CalculatedPremiumPerTerm: float64\n",
      "Number of NaN values in TotalClaims: 0\n",
      "Number of NaN values in TotalPremium: 0\n",
      "==================================================\n",
      "CLAIM SEVERITY PREDICTION MODELS\n",
      "==================================================\n",
      "\n",
      "Training Linear Regression...\n",
      "Linear Regression - RMSE: 35291.25, R²: 0.2256\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree - RMSE: 39677.89, R²: 0.0211\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest - RMSE: 34186.31, R²: 0.2733\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost - RMSE: 38537.96, R²: 0.0765\n",
      "==================================================\n",
      "CLAIM PROBABILITY PREDICTION MODELS\n",
      "==================================================\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree - Accuracy: 0.9971, Precision: 0.1667, Recall: 0.0034, F1: 0.0067, AUC: 0.9078\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest - Accuracy: 0.9971, Precision: 1.0000, Recall: 0.0017, F1: 0.0034, AUC: 0.9300\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost - Accuracy: 0.9971, Precision: 0.5000, Recall: 0.0017, F1: 0.0034, AUC: 0.9314\n",
      "==================================================\n",
      "PREMIUM PREDICTION MODELS\n",
      "==================================================\n",
      "\n",
      "Training Linear Regression...\n",
      "Linear Regression - RMSE: 129.48, R²: 0.3923\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree - RMSE: 10.38, R²: 0.9961\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest - RMSE: 12.21, R²: 0.9946\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost - RMSE: 3.98, R²: 0.9994\n",
      "==================================================\n",
      "MODEL INTERPRETABILITY - CLAIM_SEVERITY\n",
      "==================================================\n",
      "Analyzing best model: Random Forest\n",
      "\n",
      "Top 10 Most Important Features (Random Forest):\n",
      "                     feature    importance\n",
      "7   CalculatedPremiumPerTerm  11796.377515\n",
      "6                 SumInsured   7566.497860\n",
      "5         CapitalOutstanding   1408.000466\n",
      "0           RegistrationYear   1148.859164\n",
      "25     CoverCategory_encoded    870.388085\n",
      "2              cubiccapacity    772.517469\n",
      "10      TransactionMonth_num    691.134611\n",
      "11  PremiumToSumInsuredRatio    682.100767\n",
      "18       VehicleType_encoded    342.360374\n",
      "3                  kilowatts    326.899788\n",
      "==================================================\n",
      "MODEL INTERPRETABILITY - CLAIM_PROBABILITY\n",
      "==================================================\n",
      "==================================================\n",
      "RISK-BASED PREMIUM CALCULATION\n",
      "==================================================\n",
      "Risk-Based Premium Analysis (Sample of 1000 policies):\n",
      "Average Claim Probability: 0.0025\n",
      "Average Claim Severity: 16408.07\n",
      "Average Risk Premium: 54.69\n",
      "Average Total Premium (Predicted): 68.36\n",
      "Average Total Premium (Actual): 59.68\n",
      "RMSE vs Actual Premium: 216.08\n",
      "==================================================\n",
      "COMPREHENSIVE MODEL COMPARISON REPORT\n",
      "==================================================\n",
      "\n",
      "1. CLAIM SEVERITY PREDICTION MODELS\n",
      "----------------------------------------\n",
      "            Model         RMSE       R²\n",
      "    Random Forest 34186.314877 0.273306\n",
      "Linear Regression 35291.250233 0.225572\n",
      "          XGBoost 38537.964091 0.076526\n",
      "    Decision Tree 39677.892601 0.021087\n",
      "\n",
      "2. CLAIM PROBABILITY PREDICTION MODELS\n",
      "----------------------------------------\n",
      "        Model  Accuracy  Precision   Recall  F1-Score      AUC\n",
      "Decision Tree  0.997055   0.166667 0.003442  0.006745 0.907758\n",
      "Random Forest  0.997100   1.000000 0.001721  0.003436 0.930049\n",
      "      XGBoost  0.997095   0.500000 0.001721  0.003431 0.931441\n",
      "\n",
      "3. PREMIUM PREDICTION MODELS\n",
      "----------------------------------------\n",
      "            Model       RMSE       R²\n",
      "          XGBoost   3.980358 0.999426\n",
      "    Decision Tree  10.380859 0.996094\n",
      "    Random Forest  12.207061 0.994599\n",
      "Linear Regression 129.484934 0.392263\n",
      "\n",
      "4. BEST PERFORMING MODELS\n",
      "----------------------------------------\n",
      "Best Claim Severity Model: Random Forest (R² = 0.2733)\n",
      "Best Claim Probability Model: Decision Tree (F1 = 0.0067)\n",
      "Best Premium Model: XGBoost (R² = 0.9994)\n",
      "\n",
      "==================================================\n",
      "PIPELINE COMPLETED SUCCESSFULLY!\n",
      "==================================================\n",
      "\n",
      "Pipeline completed! Check the results above for detailed analysis.\n"
     ]
    }
   ],
   "source": [
    "class InsurancePricingML:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.claim_data = None  # Subset with claims > 0\n",
    "        self.features = None\n",
    "        self.target_claim_severity = None\n",
    "        self.target_claim_probability = None\n",
    "        self.target_premium = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoders = {}\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"Load and initial data inspection\"\"\"\n",
    "        try:\n",
    "            # Assuming the data is pipe-delimited based on the sample\n",
    "            self.data = pd.read_csv(file_path, delimiter='|')\n",
    "            print(f\"Data loaded successfully: {self.data.shape}\")\n",
    "            print(f\"Columns: {list(self.data.columns)}\")\n",
    "            print(f\"\\nFirst few rows:\")\n",
    "            print(self.data.head())\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def explore_data(self):\n",
    "        \"\"\"Comprehensive data exploration\"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"DATA EXPLORATION\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Basic info\n",
    "        print(f\"Dataset shape: {self.data.shape}\")\n",
    "        print(f\"\\nMissing values:\")\n",
    "        print(self.data.isnull().sum()[self.data.isnull().sum() > 0])\n",
    "        \n",
    "        # Claims analysis\n",
    "        print(f\"\\nClaims Analysis:\")\n",
    "        print(f\"Total policies: {len(self.data)}\")\n",
    "        print(f\"Policies with claims: {len(self.data[self.data['TotalClaims'] > 0])}\")\n",
    "        print(f\"Claim frequency: {len(self.data[self.data['TotalClaims'] > 0]) / len(self.data):.2%}\")\n",
    "        \n",
    "        # Target variable distributions\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # TotalClaims distribution\n",
    "        axes[0,0].hist(self.data['TotalClaims'], bins=50, alpha=0.7)\n",
    "        axes[0,0].set_title('TotalClaims Distribution')\n",
    "        axes[0,0].set_xlabel('Total Claims')\n",
    "        \n",
    "        # TotalClaims for claims > 0\n",
    "        claim_data = self.data[self.data['TotalClaims'] > 0]\n",
    "        axes[0,1].hist(claim_data['TotalClaims'], bins=30, alpha=0.7, color='orange')\n",
    "        axes[0,1].set_title('TotalClaims Distribution (Claims > 0)')\n",
    "        axes[0,1].set_xlabel('Total Claims')\n",
    "        \n",
    "        # TotalPremium distribution\n",
    "        axes[1,0].hist(self.data['TotalPremium'], bins=50, alpha=0.7, color='green')\n",
    "        axes[1,0].set_title('TotalPremium Distribution')\n",
    "        axes[1,0].set_xlabel('Total Premium')\n",
    "        \n",
    "        # CalculatedPremiumPerTerm distribution\n",
    "        axes[1,1].hist(self.data['CalculatedPremiumPerTerm'], bins=50, alpha=0.7, color='red')\n",
    "        axes[1,1].set_title('CalculatedPremiumPerTerm Distribution')\n",
    "        axes[1,1].set_xlabel('Premium Per Term')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Correlation with target variables\n",
    "        numeric_cols = self.data.select_dtypes(include=[np.number]).columns\n",
    "        print(f\"\\nCorrelation with TotalClaims:\")\n",
    "        correlations = self.data[numeric_cols].corr()['TotalClaims'].sort_values(ascending=False)\n",
    "        print(correlations[correlations.index != 'TotalClaims'].head(10))\n",
    "    \n",
    "    def feature_engineering(self):\n",
    "        \"\"\"Create new features and prepare data\"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"FEATURE ENGINEERING\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Create a copy for processing\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # Parse TransactionMonth\n",
    "        df['TransactionMonth'] = pd.to_datetime(df['TransactionMonth'])\n",
    "        df['TransactionYear'] = df['TransactionMonth'].dt.year\n",
    "        df['TransactionMonth_num'] = df['TransactionMonth'].dt.month\n",
    "        \n",
    "        # Vehicle age\n",
    "        df['VehicleAge'] = df['TransactionYear'] - df['RegistrationYear']\n",
    "        \n",
    "        # Create claim indicator\n",
    "        df['HasClaim'] = (df['TotalClaims'] > 0).astype(int)\n",
    "        \n",
    "        # Premium to sum insured ratio\n",
    "        df['PremiumToSumInsuredRatio'] = df['TotalPremium'] / (df['SumInsured'] + 1)\n",
    "        \n",
    "        # Claim to premium ratio (for policies with claims)\n",
    "        df['ClaimToPremiumRatio'] = df['TotalClaims'] / (df['TotalPremium'] + 1)\n",
    "        \n",
    "        # Engine power indicators\n",
    "        df['HighPowerEngine'] = (df['kilowatts'] > df['kilowatts'].median()).astype(int)\n",
    "        df['LargeEngine'] = (df['cubiccapacity'] > df['cubiccapacity'].median()).astype(int)\n",
    "        \n",
    "        # Province risk grouping (simplified)\n",
    "        province_risk = df.groupby('Province')['HasClaim'].mean().to_dict()\n",
    "        df['ProvinceRisk'] = df['Province'].map(province_risk)\n",
    "        \n",
    "        # Make risk grouping\n",
    "        make_risk = df.groupby('make')['HasClaim'].mean().to_dict()\n",
    "        df['MakeRisk'] = df['make'].map(make_risk)\n",
    "        \n",
    "        self.data = df\n",
    "        print(\"Feature engineering completed\")\n",
    "        print(f\"New features created: VehicleAge, HasClaim, PremiumToSumInsuredRatio, ClaimToPremiumRatio, etc.\")\n",
    "    \n",
    "    def prepare_features(self):\n",
    "        \"\"\"Prepare features for modeling\"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"FEATURE PREPARATION\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Select relevant features\n",
    "        numeric_features = [\n",
    "            'RegistrationYear', 'Cylinders', 'cubiccapacity', 'kilowatts', \n",
    "            'NumberOfDoors', 'CapitalOutstanding', 'SumInsured', \n",
    "            'CalculatedPremiumPerTerm', 'VehicleAge', 'TransactionYear',\n",
    "            'TransactionMonth_num', 'PremiumToSumInsuredRatio', 'ProvinceRisk', 'MakeRisk'\n",
    "        ]\n",
    "        \n",
    "        categorical_features = [\n",
    "            'IsVATRegistered', 'LegalType', 'Gender', 'Province', 'VehicleType',\n",
    "            'make', 'bodytype', 'AlarmImmobiliser', 'TrackingDevice', 'NewVehicle',\n",
    "            'TermFrequency', 'CoverCategory', 'CoverType', 'Product'\n",
    "        ]\n",
    "        \n",
    "        # Clean numeric columns first - handle European decimal format\n",
    "        def clean_numeric_column(series):\n",
    "            \"\"\"Clean numeric column by handling different decimal formats\"\"\"\n",
    "            if series.dtype == 'object':  # String column\n",
    "                # Replace comma with dot for decimal separator\n",
    "                cleaned = series.astype(str).str.replace(',', '.', regex=False)\n",
    "                # Convert to numeric, coercing errors to NaN\n",
    "                return pd.to_numeric(cleaned, errors='coerce')\n",
    "            else:\n",
    "                return pd.to_numeric(series, errors='coerce')\n",
    "        \n",
    "        # Apply cleaning to numeric features\n",
    "        for col in numeric_features:\n",
    "            if col in self.data.columns:\n",
    "                print(f\"Cleaning numeric column: {col}\")\n",
    "                self.data[col] = clean_numeric_column(self.data[col])\n",
    "        \n",
    "        # Also clean the target variables\n",
    "        target_columns = ['TotalClaims', 'TotalPremium', 'CalculatedPremiumPerTerm', 'SumInsured', 'CapitalOutstanding']\n",
    "        for col in target_columns:\n",
    "            if col in self.data.columns:\n",
    "                print(f\"Cleaning target column: {col}\")\n",
    "                self.data[col] = clean_numeric_column(self.data[col])\n",
    "        \n",
    "        # Handle missing values AFTER cleaning\n",
    "        for col in numeric_features:\n",
    "            if col in self.data.columns:\n",
    "                median_val = self.data[col].median()\n",
    "                if pd.isna(median_val):  # If median is NaN, use 0\n",
    "                    median_val = 0\n",
    "                self.data[col] = self.data[col].fillna(median_val)\n",
    "        \n",
    "        for col in categorical_features:\n",
    "            if col in self.data.columns:\n",
    "                self.data[col] = self.data[col].fillna('Unknown')\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        df_encoded = self.data.copy()\n",
    "        \n",
    "        for col in categorical_features:\n",
    "            if col in df_encoded.columns:\n",
    "                le = LabelEncoder()\n",
    "                df_encoded[col + '_encoded'] = le.fit_transform(df_encoded[col].astype(str))\n",
    "                self.label_encoders[col] = le\n",
    "        \n",
    "        # Select final features\n",
    "        final_features = numeric_features + [col + '_encoded' for col in categorical_features \n",
    "                                           if col in self.data.columns]\n",
    "        \n",
    "        # Remove features that don't exist\n",
    "        final_features = [f for f in final_features if f in df_encoded.columns]\n",
    "        \n",
    "        self.features = df_encoded[final_features]\n",
    "        self.target_claim_severity = df_encoded['TotalClaims']\n",
    "        self.target_claim_probability = df_encoded['HasClaim']\n",
    "        self.target_premium = df_encoded['TotalPremium']\n",
    "        \n",
    "        # Create claim severity dataset (only policies with claims > 0)\n",
    "        claim_mask = df_encoded['TotalClaims'] > 0\n",
    "        self.claim_features = self.features[claim_mask]\n",
    "        self.claim_target = self.target_claim_severity[claim_mask]\n",
    "        \n",
    "        print(f\"Final feature matrix shape: {self.features.shape}\")\n",
    "        print(f\"Claim severity dataset shape: {self.claim_features.shape}\")\n",
    "        print(f\"Features used: {list(self.features.columns)}\")\n",
    "        \n",
    "        # Display data types to verify cleaning\n",
    "        print(f\"\\nData types after cleaning:\")\n",
    "        for col in ['TotalClaims', 'TotalPremium', 'CalculatedPremiumPerTerm']:\n",
    "            if col in self.data.columns:\n",
    "                print(f\"{col}: {self.data[col].dtype}\")\n",
    "        \n",
    "        print(f\"Number of NaN values in TotalClaims: {self.data['TotalClaims'].isna().sum()}\")\n",
    "        print(f\"Number of NaN values in TotalPremium: {self.data['TotalPremium'].isna().sum()}\")\n",
    "    \n",
    "    def build_claim_severity_models(self):\n",
    "        \"\"\"Build models to predict claim severity (TotalClaims for policies with claims > 0)\"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"CLAIM SEVERITY PREDICTION MODELS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.claim_features, self.claim_target, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        models = {\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
    "            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10),\n",
    "            'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42, max_depth=6)\n",
    "        }\n",
    "        \n",
    "        severity_results = {}\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            print(f\"\\nTraining {name}...\")\n",
    "            \n",
    "            # Use scaled features for Linear Regression, original for tree-based models\n",
    "            if name == 'Linear Regression':\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                y_pred = model.predict(X_test_scaled)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            severity_results[name] = {\n",
    "                'model': model,\n",
    "                'rmse': rmse,\n",
    "                'r2': r2,\n",
    "                'predictions': y_pred,\n",
    "                'actual': y_test\n",
    "            }\n",
    "            \n",
    "            print(f\"{name} - RMSE: {rmse:.2f}, R²: {r2:.4f}\")\n",
    "        \n",
    "        self.models['claim_severity'] = models\n",
    "        self.results['claim_severity'] = severity_results\n",
    "        \n",
    "        # Plot results\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        for i, (name, result) in enumerate(severity_results.items()):\n",
    "            axes[i].scatter(result['actual'], result['predictions'], alpha=0.5)\n",
    "            axes[i].plot([result['actual'].min(), result['actual'].max()], \n",
    "                        [result['actual'].min(), result['actual'].max()], 'r--')\n",
    "            axes[i].set_xlabel('Actual')\n",
    "            axes[i].set_ylabel('Predicted')\n",
    "            axes[i].set_title(f'{name}\\nRMSE: {result[\"rmse\"]:.2f}, R²: {result[\"r2\"]:.4f}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def build_claim_probability_models(self):\n",
    "        \"\"\"Build models to predict probability of claim occurrence\"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"CLAIM PROBABILITY PREDICTION MODELS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.features, self.target_claim_probability, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        models = {\n",
    "            'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10),\n",
    "            'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, max_depth=6)\n",
    "        }\n",
    "        \n",
    "        probability_results = {}\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            print(f\"\\nTraining {name}...\")\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            probability_results[name] = {\n",
    "                'model': model,\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "                'auc': auc,\n",
    "                'predictions': y_pred,\n",
    "                'probabilities': y_pred_proba,\n",
    "                'actual': y_test\n",
    "            }\n",
    "            \n",
    "            print(f\"{name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "        \n",
    "        self.models['claim_probability'] = models\n",
    "        self.results['claim_probability'] = probability_results\n",
    "        \n",
    "        # Plot confusion matrices\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        \n",
    "        for i, (name, result) in enumerate(probability_results.items()):\n",
    "            cm = confusion_matrix(result['actual'], result['predictions'])\n",
    "            sns.heatmap(cm, annot=True, fmt='d', ax=axes[i], cmap='Blues')\n",
    "            axes[i].set_title(f'{name}\\nAccuracy: {result[\"accuracy\"]:.4f}')\n",
    "            axes[i].set_xlabel('Predicted')\n",
    "            axes[i].set_ylabel('Actual')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def build_premium_models(self):\n",
    "        \"\"\"Build models to predict premium\"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"PREMIUM PREDICTION MODELS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.features, self.target_premium, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        models = {\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
    "            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10),\n",
    "            'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42, max_depth=6)\n",
    "        }\n",
    "        \n",
    "        premium_results = {}\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            print(f\"\\nTraining {name}...\")\n",
    "            \n",
    "            # Use scaled features for Linear Regression, original for tree-based models\n",
    "            if name == 'Linear Regression':\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                y_pred = model.predict(X_test_scaled)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            premium_results[name] = {\n",
    "                'model': model,\n",
    "                'rmse': rmse,\n",
    "                'r2': r2,\n",
    "                'predictions': y_pred,\n",
    "                'actual': y_test\n",
    "            }\n",
    "            \n",
    "            print(f\"{name} - RMSE: {rmse:.2f}, R²: {r2:.4f}\")\n",
    "        \n",
    "        self.models['premium'] = models\n",
    "        self.results['premium'] = premium_results\n",
    "    \n",
    "    def model_interpretability(self, model_type='claim_severity'):\n",
    "        \"\"\"Use SHAP for model interpretability\"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(f\"MODEL INTERPRETABILITY - {model_type.upper()}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if model_type not in self.results:\n",
    "            print(f\"No results found for {model_type}\")\n",
    "            return\n",
    "        \n",
    "        # Get the best model (highest R² for regression, highest F1 for classification)\n",
    "        if model_type in ['claim_severity', 'premium']:\n",
    "            best_model_name = max(self.results[model_type].keys(), \n",
    "                                key=lambda x: self.results[model_type][x]['r2'])\n",
    "            best_model = self.models[model_type][best_model_name]\n",
    "            print(f\"Analyzing best model: {best_model_name}\")\n",
    "            \n",
    "            # Use appropriate dataset\n",
    "            if model_type == 'claim_severity':\n",
    "                X = self.claim_features\n",
    "            else:\n",
    "                X = self.features\n",
    "            \n",
    "        else:  # claim_probability\n",
    "            best_model_name = max(self.results[model_type].keys(), \n",
    "                                key=lambda x: self.results[model_type][x]['f1'])\n",
    "            best_model = self.models[model_type][best_model_name]\n",
    "            X = self.features\n",
    "        \n",
    "        # SHAP analysis\n",
    "        try:\n",
    "            if best_model_name in ['Random Forest', 'XGBoost']:\n",
    "                # For tree-based models\n",
    "                explainer = shap.TreeExplainer(best_model)\n",
    "                shap_values = explainer.shap_values(X.iloc[:1000])  # Sample for performance\n",
    "                \n",
    "                # Summary plot\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                shap.summary_plot(shap_values, X.iloc[:1000], show=False)\n",
    "                plt.title(f'SHAP Summary Plot - {best_model_name}')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Feature importance\n",
    "                feature_importance = pd.DataFrame({\n",
    "                    'feature': X.columns,\n",
    "                    'importance': np.abs(shap_values).mean(0)\n",
    "                }).sort_values('importance', ascending=False)\n",
    "                \n",
    "                print(f\"\\nTop 10 Most Important Features ({best_model_name}):\")\n",
    "                print(feature_importance.head(10))\n",
    "                \n",
    "                # Plot feature importance\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.barh(range(10), feature_importance.head(10)['importance'])\n",
    "                plt.yticks(range(10), feature_importance.head(10)['feature'])\n",
    "                plt.xlabel('Mean |SHAP value|')\n",
    "                plt.title(f'Top 10 Feature Importance - {best_model_name}')\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"SHAP analysis failed: {e}\")\n",
    "            \n",
    "            # Fallback to feature importance for tree-based models\n",
    "            if hasattr(best_model, 'feature_importances_'):\n",
    "                feature_importance = pd.DataFrame({\n",
    "                    'feature': X.columns,\n",
    "                    'importance': best_model.feature_importances_\n",
    "                }).sort_values('importance', ascending=False)\n",
    "                \n",
    "                print(f\"\\nTop 10 Most Important Features ({best_model_name}):\")\n",
    "                print(feature_importance.head(10))\n",
    "                \n",
    "                # Plot feature importance\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.barh(range(10), feature_importance.head(10)['importance'])\n",
    "                plt.yticks(range(10), feature_importance.head(10)['feature'])\n",
    "                plt.xlabel('Feature Importance')\n",
    "                plt.title(f'Top 10 Feature Importance - {best_model_name}')\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "    \n",
    "    def generate_risk_based_premium(self, sample_size=1000):\n",
    "        \"\"\"Generate risk-based premium using the formula:\n",
    "        Premium = (Predicted Probability of Claim * Predicted Claim Severity) + Expense Loading + Profit Margin\n",
    "        \"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"RISK-BASED PREMIUM CALCULATION\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Get best models\n",
    "        best_prob_model = max(self.results['claim_probability'].keys(), \n",
    "                            key=lambda x: self.results['claim_probability'][x]['f1'])\n",
    "        best_severity_model = max(self.results['claim_severity'].keys(), \n",
    "                                key=lambda x: self.results['claim_severity'][x]['r2'])\n",
    "        \n",
    "        prob_model = self.models['claim_probability'][best_prob_model]\n",
    "        severity_model = self.models['claim_severity'][best_severity_model]\n",
    "        \n",
    "        # Sample data for prediction\n",
    "        sample_data = self.features.sample(n=min(sample_size, len(self.features)), random_state=42)\n",
    "        \n",
    "        # Predict claim probability\n",
    "        claim_prob = prob_model.predict_proba(sample_data)[:, 1]\n",
    "        \n",
    "        # Predict claim severity\n",
    "        claim_severity = severity_model.predict(sample_data)\n",
    "        \n",
    "        # Calculate risk-based premium\n",
    "        expense_loading = 0.15  # 15% expense loading\n",
    "        profit_margin = 0.10    # 10% profit margin\n",
    "        \n",
    "        risk_premium = claim_prob * claim_severity\n",
    "        total_premium = risk_premium * (1 + expense_loading + profit_margin)\n",
    "        \n",
    "        # Compare with actual premiums\n",
    "        actual_premium = self.target_premium.loc[sample_data.index]\n",
    "        \n",
    "        results_df = pd.DataFrame({\n",
    "            'ClaimProbability': claim_prob,\n",
    "            'ClaimSeverity': claim_severity,\n",
    "            'RiskPremium': risk_premium,\n",
    "            'TotalPremium_Predicted': total_premium,\n",
    "            'TotalPremium_Actual': actual_premium,\n",
    "            'Difference': total_premium - actual_premium\n",
    "        })\n",
    "        \n",
    "        print(f\"Risk-Based Premium Analysis (Sample of {len(results_df)} policies):\")\n",
    "        print(f\"Average Claim Probability: {claim_prob.mean():.4f}\")\n",
    "        print(f\"Average Claim Severity: {claim_severity.mean():.2f}\")\n",
    "        print(f\"Average Risk Premium: {risk_premium.mean():.2f}\")\n",
    "        print(f\"Average Total Premium (Predicted): {total_premium.mean():.2f}\")\n",
    "        print(f\"Average Total Premium (Actual): {actual_premium.mean():.2f}\")\n",
    "        print(f\"RMSE vs Actual Premium: {np.sqrt(mean_squared_error(actual_premium, total_premium)):.2f}\")\n",
    "        \n",
    "        # Plot comparison\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.scatter(actual_premium, total_premium, alpha=0.5)\n",
    "        plt.plot([actual_premium.min(), actual_premium.max()], \n",
    "                [actual_premium.min(), actual_premium.max()], 'r--')\n",
    "        plt.xlabel('Actual Premium')\n",
    "        plt.ylabel('Predicted Premium')\n",
    "        plt.title('Actual vs Risk-Based Premium')\n",
    "        \n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.hist(results_df['Difference'], bins=30, alpha=0.7)\n",
    "        plt.xlabel('Difference (Predicted - Actual)')\n",
    "        plt.title('Premium Difference Distribution')\n",
    "        \n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.scatter(claim_prob, total_premium, alpha=0.5)\n",
    "        plt.xlabel('Claim Probability')\n",
    "        plt.ylabel('Total Premium')\n",
    "        plt.title('Claim Probability vs Premium')\n",
    "        \n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.scatter(claim_severity, total_premium, alpha=0.5)\n",
    "        plt.xlabel('Claim Severity')\n",
    "        plt.ylabel('Total Premium')\n",
    "        plt.title('Claim Severity vs Premium')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def generate_model_comparison_report(self):\n",
    "        \"\"\"Generate comprehensive model comparison report\"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"COMPREHENSIVE MODEL COMPARISON REPORT\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Claim Severity Models\n",
    "        print(\"\\n1. CLAIM SEVERITY PREDICTION MODELS\")\n",
    "        print(\"-\" * 40)\n",
    "        severity_df = pd.DataFrame({\n",
    "            'Model': list(self.results['claim_severity'].keys()),\n",
    "            'RMSE': [self.results['claim_severity'][model]['rmse'] for model in self.results['claim_severity'].keys()],\n",
    "            'R²': [self.results['claim_severity'][model]['r2'] for model in self.results['claim_severity'].keys()]\n",
    "        }).sort_values('R²', ascending=False)\n",
    "        print(severity_df.to_string(index=False))\n",
    "        \n",
    "        # Claim Probability Models\n",
    "        print(\"\\n2. CLAIM PROBABILITY PREDICTION MODELS\")\n",
    "        print(\"-\" * 40)\n",
    "        prob_df = pd.DataFrame({\n",
    "            'Model': list(self.results['claim_probability'].keys()),\n",
    "            'Accuracy': [self.results['claim_probability'][model]['accuracy'] for model in self.results['claim_probability'].keys()],\n",
    "            'Precision': [self.results['claim_probability'][model]['precision'] for model in self.results['claim_probability'].keys()],\n",
    "            'Recall': [self.results['claim_probability'][model]['recall'] for model in self.results['claim_probability'].keys()],\n",
    "            'F1-Score': [self.results['claim_probability'][model]['f1'] for model in self.results['claim_probability'].keys()],\n",
    "            'AUC': [self.results['claim_probability'][model]['auc'] for model in self.results['claim_probability'].keys()]\n",
    "        }).sort_values('F1-Score', ascending=False)\n",
    "        print(prob_df.to_string(index=False))\n",
    "        \n",
    "        # Premium Models\n",
    "        print(\"\\n3. PREMIUM PREDICTION MODELS\")\n",
    "        print(\"-\" * 40)\n",
    "        premium_df = pd.DataFrame({\n",
    "            'Model': list(self.results['premium'].keys()),\n",
    "            'RMSE': [self.results['premium'][model]['rmse'] for model in self.results['premium'].keys()],\n",
    "            'R²': [self.results['premium'][model]['r2'] for model in self.results['premium'].keys()]\n",
    "        }).sort_values('R²', ascending=False)\n",
    "        print(premium_df.to_string(index=False))\n",
    "        \n",
    "        # Best Models Summary\n",
    "        print(\"\\n4. BEST PERFORMING MODELS\")\n",
    "        print(\"-\" * 40)\n",
    "        best_severity = severity_df.iloc[0]['Model']\n",
    "        best_probability = prob_df.iloc[0]['Model']\n",
    "        best_premium = premium_df.iloc[0]['Model']\n",
    "        \n",
    "        print(f\"Best Claim Severity Model: {best_severity} (R² = {severity_df.iloc[0]['R²']:.4f})\")\n",
    "        print(f\"Best Claim Probability Model: {best_probability} (F1 = {prob_df.iloc[0]['F1-Score']:.4f})\")\n",
    "        print(f\"Best Premium Model: {best_premium} (R² = {premium_df.iloc[0]['R²']:.4f})\")\n",
    "        \n",
    "        return {\n",
    "            'claim_severity': severity_df,\n",
    "            'claim_probability': prob_df,\n",
    "            'premium': premium_df\n",
    "        }\n",
    "    \n",
    "    def run_full_pipeline(self, file_path):\n",
    "        \"\"\"Run the complete ML pipeline\"\"\"\n",
    "        print(\"Starting Insurance Risk-Based Pricing ML Pipeline...\")\n",
    "        \n",
    "        # Load and explore data\n",
    "        if not self.load_data(file_path):\n",
    "            return\n",
    "        \n",
    "        self.explore_data()\n",
    "        \n",
    "        # Feature engineering and preparation\n",
    "        self.feature_engineering()\n",
    "        self.prepare_features()\n",
    "        \n",
    "        # Build models\n",
    "        self.build_claim_severity_models()\n",
    "        self.build_claim_probability_models()\n",
    "        self.build_premium_models()\n",
    "        \n",
    "        # Model interpretability\n",
    "        self.model_interpretability('claim_severity')\n",
    "        self.model_interpretability('claim_probability')\n",
    "        \n",
    "        # Generate risk-based premium\n",
    "        risk_premium_results = self.generate_risk_based_premium()\n",
    "        \n",
    "        # Generate comprehensive report\n",
    "        model_comparison = self.generate_model_comparison_report()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        return {\n",
    "            'risk_premium_results': risk_premium_results,\n",
    "            'model_comparison': model_comparison,\n",
    "            'models': self.models,\n",
    "            'results': self.results\n",
    "        }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the pipeline\n",
    "    pipeline = InsurancePricingML()\n",
    "    \n",
    "    # Run the complete pipeline\n",
    "    # Replace 'your_data_file.csv' with your actual file path\n",
    "    results = pipeline.run_full_pipeline('../data/cleaned/MachineLearningRating_v3.txt')\n",
    "    \n",
    "    print(\"\\nPipeline completed! Check the results above for detailed analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
